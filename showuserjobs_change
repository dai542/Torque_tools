#!/usr/bin/env python3
# Author: DJ

import subprocess
import re
from collections import defaultdict
import argparse

# Helper function to run qstat -f and capture output
def get_qstat_output():
    try:
        result = subprocess.run(["qstat", "-f"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        if result.returncode != 0:
            print(f"Error running qstat: {result.stderr}")
            return None
        return result.stdout.splitlines()
    except Exception as e:
        print(f"Exception while running qstat: {e}")
        return None

# Main function to process job statistics
def process_jobs(filter_user=None):
    lines = get_qstat_output()
    if not lines:
        return

    # Initialize data structures
    user_data = defaultdict(lambda: {"running": 0, "queued": 0, "cores": 0, "running_jobs": [], "queued_jobs": []})
    total_running = 0
    total_queued = 0
    total_cores = 0

    # Variables to track current job details
    current_user = None
    current_queue = None
    current_job_id = None
    current_state = None
    current_ncpus = None

    for line in lines:
        line = line.strip()

        # Extract Job_Owner (username)
        match = re.match(r"Job_Owner\s*=\s*(\S+)@", line)
        if match:
            current_user = match.group(1)

        # Extract job_state (R/Q)
        match = re.match(r"job_state\s*=\s*(\S+)", line)
        if match:
            current_state = match.group(1)

        # Extract Resource_List.ncpus (cores)
        match = re.match(r"Resource_List\.ncpus\s*=\s*(\d+)", line)
        if match:
            current_ncpus = int(match.group(1))

        # Extract queue name
        match = re.match(r"queue\s*=\s*(\S+)", line)
        if match:
            current_queue = match.group(1)

        # Extract Job Id
        match = re.match(r"Job Id:\s*(\d+)\.", line)
        if match:
            # If we encounter a new Job Id, process the previous job first
            if current_user and current_queue and current_job_id and current_state and current_ncpus is not None:
                job_info = f"{current_queue}({current_job_id})"
                if current_state == "R":
                    user_data[current_user]["running"] += 1
                    total_running += 1
                    user_data[current_user]["running_jobs"].append(job_info)
                elif current_state == "Q":
                    user_data[current_user]["queued"] += 1
                    total_queued += 1
                    user_data[current_user]["queued_jobs"].append(job_info)
                user_data[current_user]["cores"] += current_ncpus
                total_cores += current_ncpus

            # Reset variables for the next job
            current_job_id = match.group(1)
            current_state = None
            current_ncpus = None
            current_queue = None

    # Process the last job if it exists
    if current_user and current_queue and current_job_id and current_state and current_ncpus is not None:
        job_info = f"{current_queue}({current_job_id})"
        if current_state == "R":
            user_data[current_user]["running"] += 1
            total_running += 1
            user_data[current_user]["running_jobs"].append(job_info)
        elif current_state == "Q":
            user_data[current_user]["queued"] += 1
            total_queued += 1
            user_data[current_user]["queued_jobs"].append(job_info)
        user_data[current_user]["cores"] += current_ncpus
        total_cores += current_ncpus

    # Filter data by user if specified
    if filter_user:
        filtered_data = {filter_user: user_data.get(filter_user, {})}
        if not filtered_data[filter_user]:
            print(f"No jobs found for user '{filter_user}'.")
            return
        user_data = filtered_data

    # Calculate dynamic column widths
    max_username_len = max(len(user) for user in user_data.keys())
    max_running_jobs_list_len = max(
        len(", ".join(data["running_jobs"])) if data["running_jobs"] else 1
        for data in user_data.values()
    )
    max_queued_jobs_list_len = max(
        len(", ".join(data["queued_jobs"])) if data["queued_jobs"] else 1
        for data in user_data.values()
    )

    # Define column widths
    username_width = max(max_username_len, len("Username"))
    running_jobs_width = max(len("Running Jobs"), 12)
    queued_jobs_width = max(len("Queued Jobs"), 12)
    total_cores_width = max(len("Total Cores"), 12)
    running_jobs_list_width = max(max_running_jobs_list_len, len("Running Jobs List"))
    queued_jobs_list_width = max(max_queued_jobs_list_len, len("Queued Jobs List"))

    # Print header with dynamic column widths
    header = (
        f"{'Username':<{username_width}} "
        f"{'Running Jobs':<{running_jobs_width}} "
        f"{'Queued Jobs':<{queued_jobs_width}} "
        f"{'Total Cores':<{total_cores_width}} "
        f"{'Running Jobs List':<{running_jobs_list_width}} "
        f"{'Queued Jobs List':<{queued_jobs_list_width}}"
    )
    print("PBS Job Statistics -", subprocess.check_output(["date"]).decode().strip())
    print(header)
    print("=" * len(header))

    # Print user statistics
    for user, data in sorted(user_data.items()):
        running_jobs_str = ", ".join(data["running_jobs"]) if data["running_jobs"] else "-"
        queued_jobs_str = ", ".join(data["queued_jobs"]) if data["queued_jobs"] else "-"
        print(
            f"{user:<{username_width}} "
            f"{data['running']:<{running_jobs_width}} "
            f"{data['queued']:<{queued_jobs_width}} "
            f"{data['cores']:<{total_cores_width}} "
            f"{running_jobs_str:<{running_jobs_list_width}} "
            f"{queued_jobs_str:<{queued_jobs_list_width}}"
        )

    if not filter_user:
        print("-" * len(header))
        totals_line = (
            f"{'TOTAL':<{username_width}} "
            f"{total_running:<{running_jobs_width}} "
            f"{total_queued:<{queued_jobs_width}} "
            f"{total_cores:<{total_cores_width}} "
            f"{'-':<{running_jobs_list_width}} "
            f"{'-':<{queued_jobs_list_width}}"
        )
        print(totals_line)
        print("-" * len(header))
    print("Report generated on", subprocess.check_output(["date"]).decode().strip())
    print("For detailed job information, use: qstat -f")

def parse_args():
    parser = argparse.ArgumentParser(description="Generate PBS job statistics.")
    parser.add_argument(
        "-u", "--user",
        help="Filter statistics by a specific username.",
        type=str,
        default=None
    )
    return parser.parse_args()

if __name__ == "__main__":
    args = parse_args()
    process_jobs(filter_user=args.user)
